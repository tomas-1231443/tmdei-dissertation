% Chapter 3
\chapter{Method and Implementation}
\label{chap:Chapter3}

This chapter details the methodology employed to tackle the problem, providing an overview of the technologies utilized and the implementation process. 

It consists of two sections: the first describes the method's design and proposed solutions, while the second covers the proof of concept, including implementation and optimization in a live environment.

\section{Method}
This section describes the methodological foundation of the project. 
It begins by presenting the technologies used and continues with an outline of three distinct solution strategies to the problem. 

Each approach is described through its pipeline and architectural design, offering a comparative view of possible solutions.

\subsection{Technological Overview}

The solution will be developed and implemented using the Python programming language, version 3.10.12. 
The following libraries are expected to be used throughout the development of the project:

\begin{itemize}
    \item \textbf{scikit-learn} (version 1.6.1): This library will be used for building machine learning models, including the Random Forest model. It provides necessary functionalities for model training, testing, and performance evaluation.
    
    \item \textbf{pandas} (version 2.2.3): Pandas will be used for data manipulation and analysis, particularly for handling, processing, and cleaning the alert datasets. It provides efficient data structures for handling large amounts of structured data.

    \item \textbf{fastapi} (version 0.115.11): FastAPI will be used to create the necessary APIs for data flow between the components. It will expose endpoints for the system, allowing real-time predictions and feedback from analysts to be communicated between the machine learning models and the IBM SOAR interface.

    \item \textbf{matplotlib} (version 3.10.1): Matplotlib will be used to generate plots and graphs, particularly for data exploration, visualizing model performance, and evaluating results. It will assist in identifying patterns in the data and understanding how well the model is classifying the security alerts.

    \item \textbf{SentenceTransformer} (likely needed): SentenceTransformer will be used for text vectorization, particularly for converting textual data such as alert descriptions and analyst comments into numerical embeddings. These embeddings will be used as inputs to machine learning models for better understanding and classification of textual data.

\end{itemize}


\subsection{Problem-Solving Approaches}
This subsection analyzes three distinct approaches to tackling the identified problem. 
It outlines the specific methodologies employed for each approach, detailing the pipeline process involved and the architectural framework that supports its implementation.

\paragraph{Pipeline}

The pipeline shown in Figure~\ref{fig:general_solution_pipeline} represents the general flow of data through various stages of the system. 
This flow starts with the ingestion of raw security alert data, continues through preprocessing, and is ultimately processed by a machine learning model to generate predictions. 
These predictions are then presented on the IBM SOAR dashboard, where analysts can review them and provide feedback, which is used to improve the model. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ch3/assets/general_solution_pipeline.png}
    \caption{General Pipeline for all Three Solutions}
    \label{fig:general_solution_pipeline}
\end{figure}

This pipeline remains largely the same across all solutions, with the exception of section \texttt{C}, where the machine learning model varies depending on the solution. 
While the overall structure of the pipeline is consistent, the type of model used in section \texttt{C} determines the specific prediction process and outputs.

To interpret the figure, a reader should understand the following stages in the pipeline:
\begin{itemize}
    \item \textbf{Section A:} Raw security alerts are collected from various sources, such as SIEM systems, IDS, and firewalls. The data is then standardized to ensure consistency.
    \item \textbf{Section B:} The collected data undergoes preprocessing, which includes cleaning, normalization, and feature extraction.
    \item \textbf{Section C:} This section involves the machine learning model. The specific model used here varies depending on the solution, and it generates predictions based on the preprocessed data.
    \item \textbf{Section D:} Finally, the predictions are displayed on the IBM SOAR dashboard. Analysts can provide feedback on the predictions, and this feedback is used to improve the model over time.
\end{itemize}

The diagram helps visualize how the raw data moves through the system and how the predictions are continuously refined with feedback from the analysts.

\subsubsection{Random Forest with Reinforcement Learning Feedback Loop}

The first solution proposed in this study is a two-layered machine learning system that integrates a Random Forest model with a Reinforcement Learning feedback loop. 

This solution addresses the problem using a pre-trained RF model on historical data combined with an RL model that refines predictions based on analyst feedback.
This integration of \underline{RF with RL} contributes to the model's adaptability, making it highly responsive to new threats.

\paragraph{Design} 

The RF model serves as the decision-making core, trained on a historical dataset of security alerts to classify incoming alerts by taxonomy and priority—\hyperref[objective3]{Objective 3}.

While the RF model provides strong initial predictions, it struggles to adapt to new attack vectors not represented in its training data. 
To address this, the RL model enhances the predictions made by the RF model and evaluates alerts as false positives or true positives, using feedback from security analysts.

The \underline{implementation complexity} of this solution is considered \underline{moderate}, as it does not involve highly intricate algorithms or architectures. 
However, the necessity to implement and integrate two distinct models—a RF for initial predictions and a RL model for feedback-driven refinement—adds an additional layer of complexity. 

Key features of this solution include:
\begin{itemize}
    \item The RL model adjusts its parameters through a continuous feedback loop, improving classification and generating confidence scores.
    \item This dynamic learning process ensures the system is able to handle both \underline{\texttt{cold start}} issues effectively (thanks to the pre-trained RF model) and false positives in real-time.
    \item The system's \underline{adaptability} to new threats is \underline{high via the RL model} and helps manage false positives by learning patterns of false positives or true positives, refining its algorithms, and potentially reducing analysts' workloads.
    \item Designed to efficiently manage and analyze real-time alerts generated from a diverse range of log sources—\hyperref[objective4]{Objective 4}.
\end{itemize}

The \underline{interpretability} of this solution is considered \underline{moderate} due to the significant role played by AI in its decision-making processes. 
The RF model, being a supervised learning algorithm, provides a level of transparency as its outputs can be traced back to the quality and features of the historical dataset used for training. 

However, integrating RL complicates interpretability. RL's iterative feedback and rewards lead to less transparent reasoning, making analyzing and communicating insights challenging.

Integrating this solution with \underline{IBM SOAR} is relatively \underline{easy and straightforward}. 
By relying on the API endpoints provided by this solution, IBM SOAR can seamlessly communicate with the solution platform.
This is vital for enhancing the overall effectiveness of the solution—\hyperref[objective5]{Objective 5}. 

IBM SOAR provides customization of dashboards presented to analysts, enabling:

\begin{itemize}
    \item Creation of custom fields where analysts can view the solution's outputs and mark them as correct or incorrect.
    \item Feedback from analysts, which is crucial for the RL model to learn from mistakes and improve over time.
\end{itemize}

This feedback loop supports continuous refinement and enhances accuracy for future predictions. 
Overall, this strategy leverages the strengths of supervised and reinforcement learning to create a robust solution for security alert triage. 
It enhances operational efficiency and threat response capabilities by:

\begin{itemize}
    \item Minimizing false positives through continuous improvement.
    \item Allowing integration with IBM SOAR to evaluate and test the solution's effectiveness in categorizing alerts and minimizing false positives—\hyperref[objective6]{Objective 6}.
\end{itemize}

\paragraph{Pipeline} 

The illustration in Figure~\ref{fig:solution1_c} corresponds to section \texttt{C} of the general pipeline in Figure~\ref{fig:general_solution_pipeline}. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{ch3/assets/solution1_C.png}
    \caption{Part C of the General Pipeline for the Random Forest with Reinforcement Learning Feedback Loop Solution}
    \label{fig:solution1_c}
\end{figure}

This figure provides a detailed representation of the machine learning model's specific implementation for this solution. 

It elaborates on the processes and components that occur within section \texttt{C}, as outlined in the general pipeline, showcasing the unique aspects of this solution's approach to data processing and prediction generation.

\subsubsection{End-to-End Deep Learning Classifier with Feature Fusion}
The second solution in this study employs a deep neural network (DNN) model trained end-to-end on labeled security alert data, based on historical alerts dataset—\hyperref[objective3]{Objective 3}. 

Unlike solution one, which uses a pre-trained RF model, this approach processes raw SIEM logs, analyst comments, and metadata through the DNN's attention layers to automatically extract features and classify data, eliminating the need for manual feature engineering.

While solution one adapts to new threats with a reinforcement learning feedback loop, solution two relies solely on the DNN model, necessitating training on a comprehensive dataset before deployment. 
The DNN excels in complex feature extraction environments but requires periodic retraining based on analyst feedback.

\paragraph{Design}

In this solution, the \underline{DNN model} processes raw security alert data directly, leveraging attention mechanisms to identify and prioritize critical features like alert descriptions, origins, and metadata. 

The attention layers enhance the model's ability to focus on relevant patterns, improving classification accuracy and adaptability. 

By automating feature extraction, this approach streamlines the pipeline, reducing dependency on domain-specific preprocessing techniques.

Key aspects of this solution are:
\begin{itemize}
    \item The DNN model takes in raw security alert data, which is vectorized, and outputs predictions on alert taxonomy, priority, false positive status, and confidence score.
    \item The DNN model's \underline{adaptability} is \underline{moderate} and depends on the training data's quality and diversity. Once trained, it performs well on known data but is less responsive to new attack patterns unless retrained with fresh data.
    \item Solution two faces challenges with cold start problems, as the DNN model requires a substantial amount of labeled training data before it can begin making accurate predictions. Unlike solution one, which benefits from the pre-trained RF model, this solution requires extensive training before it can function effectively.
    \item Engineered to effectively process and evaluate real-time alerts originating from a wide variety of log sources—\hyperref[objective4]{Objective 4}.
\end{itemize}

The \underline{implementation complexity} of solution two is considered \underline{high} due to the extensive computational resources required to train the DNN model. 
Training a deep neural network, especially one that handles raw alert data with attention mechanisms, demands significant time and resources, making it more complex to implement.

The \underline{interpretability} of the solution is \underline{low}, primarily because the DNN model operates as a "black box". 
While it offers powerful predictions, the model's inner workings are difficult to explain, particularly when attention layers are involved, making it harder to interpret why certain predictions were made.

This solution integrates with IBM SOAR for real-time feedback and performance evaluation—\hyperref[objective5]{Objective 5}, allowing analysts to review predictions and provide feedback, which is subsequently used for periodic retraining to assess and validate the solution's capability in classifying alerts and reducing the occurrence of false positives—\hyperref[objective6]{Objective 6}.

\subsubsection{Rule-Augmented Decision Tree with Feedback Aggregation}

The third solution proposed in this study integrates static expert rules with a lightweight \underline{\gls{DTC}}. 
This hybrid system uses a rule engine to pre-filter known benign or critical alert patterns before passing any unknown or ambiguous cases to the \underline{\gls{DTM}}. 

The rules provide initial filtering for quick decisions on clear alerts. For complex cases, the DTC predicts based on available data. 
Feedback is reviewed in batches, enabling periodic updates to the rule base and retraining of the decision tree.

\paragraph{Design}

This solution combines the benefits of domain-specific rules with machine learning.
It starts with a rule engine that quickly processes alerts based on known patterns, tagging them as benign or critical and minimizing the need for further analysis. 
This approach is efficient in environments with well-defined, static patterns. 
This solution will be designed to ingest data from a variety of log sources, including SIEM systems and other security tools—\hyperref[objective4]{Objective 4}.

The rule engine will preprocess and filter alerts from these sources, leveraging predefined rules to handle known patterns efficiently, while less adaptive, predefined rules to filter known benign patterns, ensuring a baseline reduction in false positives. 

For alerts that don't fit predefined rules, the DTC classifies them using features from raw data, allowing the system to manage both known and unknown patterns while balancing interpretability and accuracy. 

The DTC works with a clean, segmented dataset to differentiate between alerts that match known patterns and those requiring further analysis—\hyperref[objective3]{Objective 3}.

Key features of this solution include:
\begin{itemize}
    \item The rule engine filters known benign or critical patterns before passing uncertain alerts to the DTC. This approach reduces the overall processing time and helps prioritize more ambiguous cases.
    \item \underline{Feedback} is logged and applied asynchronously, meaning that the system doesn't update in real-time. Instead, the rule base is updated, and the decision tree is retrained on a \underline{periodic basis (e.g., weekly)}. This ensures that the system evolves over time but does not immediately adjust to new threats in real-time.
    \item The system's ability to \underline{handle new and evolving threats} is \underline{low}, as it depends on manually updating the rule base to address new threats.
    \item \underline{\textit{Cold start}} handling is excellent because the rules-based filtering system can operate immediately without requiring training, and the DTC is lightweight enough to be quickly deployed after the initial setup.
\end{itemize}

The \underline{implementation complexity} of this solution is \underline{low}, as it uses well-understood decision tree models and a simple rule engine. 
This makes it relatively \underline{easy to implement} when compared to the other solutions. 
However, the trade-off is that the DTC may not be as powerful as deep learning-based models or even RL models when dealing with complex, high-dimensional data.

The \underline{interpretability} of this solution is considered \underline{high}. 
Both the rule engine and the decision tree are inherently interpretable, allowing analysts to understand the reasoning behind the classifications. 
This makes it particularly useful in environments where auditability and transparency are important. 
However, the model's inability to \underline{adapt} in real-time can make it \underline{less suitable} for \underline{rapidly evolving attack patterns}.

Integrating this solution with \underline{IBM SOAR} is \underline{straightforward}, allowing for seamless communication between the alert system and the dashboard used by analysts. 
Alerts classified by the rule engine and decision tree are sent to the IBM SOAR dashboard, where analysts can review predictions and provide feedback—\hyperref[objective5]{Objective 5}.
The feedback is stored and reviewed periodically to refine the rules and retrain the decision tree. 

\subsubsection{Architecture}

The diagram in Figure~\ref{fig:architecture} illustrates the architecture for all solutions.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ch3/assets/archquiteture.png}
    \caption{Architecture of the Random Forest with Reinforcement Learning Feedback Loop Solution}
    \label{fig:architecture}
\end{figure}

It's organized into three major sections:
\begin{enumerate}
    \item \textbf{Analyst Device}: This device acts as the point of interaction where security analysts review and manage alerts. Represents the user interface. The analyst logs into the system through the \textbf{Authentication} component, enabling access to the dashboard.
    
    \item \textbf{IBM SOAR Server}: The IBM SOAR Server is the central system for managing security alerts. The server sends requests to the \textbf{Bot Container} through the \texttt{\textbackslash predict} endpoint, triggering the alert classification process. Once the alert is processed, the \texttt{\textbackslash feedback} endpoint is used to receive the analyst's input for further training of the RL model.
    
    \item \textbf{Dedicated Company Server}: The \textbf{Dedicated Company Server} hosts the \textbf{Bot Container}, which is deployed on a \textbf{Virtual Machine (VM)}. This container is responsible for the core functionality of the solution, consisting of three main components:
    \begin{itemize}
        \item \textbf{API Gateway}: This component serves as the entry point for receiving requests from the IBM SOAR Server and handling communication between the components inside the bot container. It processes the incoming alert data and forwards it to the appropriate modules.
        \item \textbf{Pre-Processing Module}: This module cleans and prepares the incoming alert data, extracting features and transforming them into a suitable format for the model.
        \item \textbf{Machine Learning Module}: The \textbf{Machine Learning Module} applies the \gls{RF} model to classify the alert. These predictions are then further refined through the \gls{RL} model.
    \end{itemize}
\end{enumerate}

This architecture is designed to be modular and scalable, allowing for easy integration with existing systems and the ability to adapt to evolving security threats.


%----------------------------------------------------------------------------------------

\subsection{Comparative Analysis}
Table~\ref{tab:solution_comparison} presents a comparison of the three proposed approaches based on key evaluation criteria. 
The goal is to assess their suitability in the context of a real-world SOC environment, taking into consideration implementation complexity, adaptability, performance, interpretability, and integration potential.

\captionsetup[table]{font=small} % Set the caption font size
\scriptsize % Reduce the font size for the table content
\begin{longtable}{@{}P{3cm}P{3cm}P{4cm}P{4cm}@{}}
    \caption{Comparison of Proposed Solutions}
    \label{tab:solution_comparison} \\
    \toprule
    \textbf{Criteria} & \textbf{\gls{RF} + \gls{RL}} & \textbf{\gls{DNN}} & \textbf{Rules + Decision Tree} \\
    \midrule
    \endfirsthead

    \toprule
    \textbf{Criteria} & \textbf{\gls{RF} + \gls{RL}} & \textbf{\gls{DNN}} & \textbf{Rules + Decision Tree} \\
    \midrule
    \endhead

    \bottomrule
    \endfoot

    \bottomrule
    \endlastfoot

    Architecture Type & \gls{RF} + \gls{RL} (Two-layer) & \gls{DNN} & Rule-based + Decision Tree \\
    \vspace{0.2cm}
    Implementation Complexity & Moderate & High & Low \\
    \vspace{0.2cm}
    Adaptability to New Threats & High (via \gls{RL}) & Moderate (via retraining) & Low (manual updates) \\
    \vspace{0.2cm}
    Learning from Feedback & Online (via \gls{RL}) & Periodic retraining & Batch/manual integration \\
    \vspace{0.2cm}
    Cold Start Handling & Excellent (\gls{RF} pre-trained) & Poor & Excellent (rules pre-set) \\
    \vspace{0.2cm}
    Interpretability & Moderate & Low & High \\
    \vspace{0.2cm}
    Scalability & High & High & Moderate \\
    \vspace{0.2cm}
    Integration with SIEM (IBM SOAR) & Easy & Easy & Easy \\
    \vspace{0.2cm}
    False Positive Reduction & Adaptive (confidence scoring) & Model confidence only & Rigid (rule-defined) \\
    \vspace{0.2cm}
    Performance in Evolving Scenarios & High & Moderate & Low \\
    
\end{longtable}

\normalsize

Solution 1 offers the best combination of \textbf{moderate implementation complexity} and \textbf{high adaptability}. 
Its use of a pre-trained RF model combined with a \textbf{Reinforcement Learning (RL)} feedback loop allows the system to continuously learn and adapt in real-time. 
This continuous learning process ensures the solution remains effective in dynamic and rapidly evolving environments, handling new threats efficiently. 
The \textbf{moderate complexity} comes from integrating the two models, but this is outweighed by its high scalability and ability to adjust based on new data.

Solution 2, while \textbf{highly scalable}, has \textbf{high implementation complexity} due to the need for substantial computational resources to train the DNN. 
Although it offers excellent feature extraction capabilities, its \textbf{moderate adaptability} limits its response to new threats. 
The DNN requires retraining with new data, making it slower and less responsive compared to Solution 1's real-time learning.

In contrast, Solution 3 is \textbf{easy to implement} and offers \textbf{high interpretability} due to its rule-based system and decision trees. 
However, its \textbf{low adaptability} makes it unsuitable for handling evolving threats, as it depends on manual updates and cannot learn in real time. 
While the simplicity of this approach is beneficial in static environments, it fails to scale effectively in more complex, dynamic security landscapes.

In terms of performance, Solution 1 excels in \textbf{performance in evolving scenarios}, making it the most suitable for fast-changing environments. 
Solution 2 performs \textbf{moderately} in this regard, with slower adjustments compared to Solution 1. 
Solution 3, being static, performs \textbf{poorly} in evolving scenarios and requires manual intervention to remain effective.

Considering the trade-offs, \textbf{Solution 1} stands out as the optimal choice, balancing scalability, adaptability, and complexity. 
Its ability to evolve with emerging threats makes it the most reliable solution for real-time alert classification in dynamic cybersecurity environments.

\section{Proof of Concept}
This section presents the practical implementation of the proposed solution, including the setup of the test environment, preparation of the dataset, and execution of the ML models. It aims to demonstrate the feasibility and performance of the selected approach under realistic conditions.

\subsection{Data Processing}
This section outlines the process of refining the raw data, corresponding to phase B in the solution pipeline.

As previously mentioned, Solution One was the best choice among the three alternatives.

To implement this solution effectively, ArtResilia provided a dataset of security alerts generated by its SOC. 

This dataset, covering the period from February 9, 2022, to January 31, 2025, encompasses various alerts categorized by attributes, such as priority and taxonomy. 
The primary goal of the data processing phase was to prepare this raw data for training ML models to predict the priority and taxonomy of alerts based on the textual descriptions associated with each alert.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ch3/assets/dataset_original.png}
    \caption{Original Dataset Before Preprocessing}
    \label{fig:dataset_original}
\end{figure}

Figure~\ref{fig:dataset_original} illustrates the original dataset before preprocessing.
The dataset\footnote{For privacy reasons, the actual data has been censored or altered to ensure confidentiality.} contains 99,722 rows, each representing a security alert.

To prepare the data for training ML models, several key preprocessing steps were performed:

\paragraph{First Step}
Rows missing data in "Priority" or "Taxonomy" were removed, retaining only the essential columns: "Description", "Priority", and "Taxonomy". 
These columns provide the text for training and the target labels.

Listing~\ref{lst:first_preprocessing} shows the Python code snippet used for this initial preprocessing step.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
df = df[(df['Source'] != 'Other') & (df['Source Alert Rule Name'].notna())]
required_columns = ["Description", "Priority", "Taxonomy"]
df = df[required_columns]
df = df.dropna(subset=required_columns)
\end{minted}
\captionof{listing}{Python Code Snippet for the First Part of Preprocessing the Dataset.}
\label{lst:first_preprocessing}
\end{minipage}
\vspace{0.1cm}

\paragraph{Second Step}
Alerts with a Priority of "P4" or a Taxonomy labeled as "Other" were also excluded as these were deemed less relevant for the model's prediction task. 
To address class imbalance in the Taxonomy column, random oversampling was performed. 
This involved ensuring that smaller categories had enough examples for the model by duplicating instances from underrepresented taxonomies until they matched the size of the largest category.

Listing~\ref{lst:second_preprocessing} provides the Python code snippet used for the second preprocessing step, which includes filtering and oversampling to address class imbalance in the dataset. 

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
df = df[(df["Priority"] != "P4") & (df["Taxonomy"].str.lower() != "other")]
taxonomy_counts = df["Taxonomy"].value_counts()
max_len = taxonomy_counts.max()
oversampled_dfs = []
for tax, count in taxonomy_counts.items():
    sub_df = df[df["Taxonomy"] == tax]
    if count < max_len:
        diff = max_len - count
        extra_rows = sub_df.sample(n=diff, replace=True, random_state=42)
        sub_df = pd.concat([sub_df, extra_rows], ignore_index=True)
    oversampled_dfs.append(sub_df)
df = pd.concat(oversampled_dfs, ignore_index=True)
\end{minted}
\captionof{listing}{Python Code Snippet for the Second Part of Preprocessing the Dataset.}
\label{lst:second_preprocessing}
\end{minipage}
\vspace{0.1cm}

By applying the preprocessing code above from steps one and two, the dataset was reduced from its original 99,722 rows, representing security alerts, to approximately 81,732 rows.
However, after the oversampling process, the dataset was expanded to around 173,637 rows, ensuring a balanced representation of all taxonomies.

\paragraph{Third Step}

The "Description" column, which contains raw text data, was also cleaned. 
Unnecessary formatting was removed as well as special characters, and irrelevant sections (such as URLs and IBM SOAR links). 
It also handled tasks like stripping extra whitespace and removing HTML tags, ensuring the text was in a consistent and usable format for the machine learning pipeline.

Listing~\ref{lst:third_preprocessing} shows the Python code snippet used for this third preprocessing step.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
df["Description"] = df["Description"].progress_apply(clean_text)
\end{minted}
\captionof{listing}{Python Code Snippet for the Third Part of Preprocessing the Dataset.}
\label{lst:third_preprocessing}
\end{minipage}
\vspace{0.1cm}

The code snippet presented above applies the \texttt{clean\_text} function uniformly to all entries within the "Description" column of the dataset, ensuring consistent preprocessing of textual data for subsequent machine learning tasks.

The rules defined for normalizing the description text will be detailed in the next section, where the \texttt{clean\_text} function is explained.

\paragraph{Fourth Step}

Finally, the "Priority" and "Taxonomy" labels were stripped of any leading or trailing spaces to ensure consistency in the dataset. 

Listing~\ref{lst:fourth_preprocessing} shows the Python code snippet used for this final preprocessing step.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
df["Priority"] = df["Priority"].astype(str).str.strip()
df["Taxonomy"] = df["Taxonomy"].astype(str).str.strip()
\end{minted}
\captionof{listing}{Python Code Snippet for the Fourth Part of Preprocessing the Dataset.}
\label{lst:fourth_preprocessing}
\end{minipage}
\vspace{0.1cm}

These preprocessing steps ensure that the dataset is clean, balanced, and properly formatted, making it ready for use in the ML models. 
The combination of filtering, oversampling, text cleaning, and label processing prepares the data for training while addressing potential issues such as class imbalance and noisy raw data.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ch3/assets/dataset_processed.png}
    \caption{Original Dataset After Preprocessing}
    \label{fig:dataset_processed}
\end{figure}

Figure~\ref{fig:dataset_processed} illustrates the dataset\footnotemark[\value{footnote}] after preprocessing, showcasing the difference between the original and processed versions.

\subsection{Data Normalization}
Data normalization typically refers to the process of transforming data into a common scale to improve the performance and accuracy of machine learning models. 

In this project, normalization was applied specifically to the "Description" column, which contains the raw text data. 

This is crucial, as natural language data can contain noise, irrelevant characters, and inconsistencies that can negatively impact model training and performance. 

Unlike the Priority and Taxonomy columns, which are already in categorical formats suitable for ML models, the Description column required more extensive processing to make it usable for training.

As stated in the previous section, the normalization process was performed using a function called \texttt{clean\_text}, which was designed to normalize the raw text in the Description column. 
This function specifically targets common issues in textual data, such as extraneous formatting, unwanted characters, and irrelevant content.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ch3/assets/redacted_description_text.png}
    \caption{Redacted Description Text}
    \label{fig:redacted_description_text}
\end{figure}

Figure~\ref{fig:redacted_description_text} presents a redacted\footnote{For privacy reasons, the actual data has been censored or altered to ensure confidentiality.} visualization that exemplifies the typical format of a description text.
The formatting of this description may differ based on the source of the alert, highlighting the diverse origins and structures of the data. 
To address these variations, the \texttt{clean\_text} function was created to standardize the presentation of the text data, ensuring it remains consistent regardless of its source.

The \texttt{clean\_text} function performs several key operations:

\begin{itemize}
    \item \textbf{Extract Relevant Content:} Identifies and retains the "Description" section, removing irrelevant sections like "Taxonomy" or "References" if present.
    \item \textbf{Remove Unwanted Characters:} Cleans special symbols, color tags, code markers, HTML tags, and URLs to retain only meaningful content.
    \item \textbf{Text Cleaning:} Strips extra spaces, removes irrelevant phrases (e.g., "action:" or "related evidences:"), and ensures consistent formatting.
    \item \textbf{Handle Rule Name:} Captures and formats rule names with associated narratives as \texttt{<Rule Name> - <Narrative>} for clarity.
    \item \textbf{Final Output:} Returns a cleaned, normalized description.
\end{itemize}

By applying a normalizing function to the Description column helps achieve consistency and reduce noise in the training text data.
The Priority and Taxonomy columns did not require the same normalization process, as they are categorical and do not need extensive text processing.

\subsection{Dataset Division}
Dataset Division refers to how the dataset is split into subsets used for training, validation, and testing. 

This division is crucial because it allows the model to be trained on one subset of the data while ensuring that the model's performance is evaluated on unseen data. 

This prevents overfitting, where the model performs well on training data but fails to generalize to new, unseen data. 

Similarly, proper dataset division also avoids underfitting, where the model might not learn enough from the training data to perform well.
\clearpage
In ML, the dataset is typically divided into three parts:
\begin{itemize}
    \item \textbf{Training Set:} Used to train the model.
    \item \textbf{Validation Set:} Used to tune the model's hyperparameters and prevent overfitting during training.
    \item \textbf{Test Set:} Used to evaluate the final model's performance after training is complete.
\end{itemize}

In this project, the dataset was divided as follows:

\begin{itemize}
    \item \textbf{Training and Test Split:} The data was split into 70\% for training and 30\% for testing. This ratio strikes a balance between providing enough data for the model to learn from, while still maintaining a sufficient amount of data to test its generalization ability. This approach was chosen to maximize the model's ability to generalize to unseen data while preventing overfitting.
\end{itemize}

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=stratify_labels)
\end{minted}
\captionof{listing}{Splitting Dataset.}
\label{lst:dataset_split}
\end{minipage}
\vspace{0.1cm}

\begin{itemize}
    \item \textbf{Stratified Sampling:} The split was performed using stratified sampling, ensuring that the proportion of each class in Priority and Taxonomy was maintained across the training and test sets. This helps avoid bias in the dataset and ensures that both the training and test sets have representative distributions of all classes.
\end{itemize}

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
stratify_labels = [tuple(row) for row in Y]
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=stratify_labels)
\end{minted}
\captionof{listing}{Stratified Sampling.}
\label{lst:stratified_sampling}
\end{minipage}
\vspace{0.1cm}

This stratified split is particularly important for imbalanced datasets, as it ensures that each class is proportionally represented in both the training and testing subsets, thereby improving the model's ability to generalize and minimizing bias toward the majority class.

\begin{itemize}
    \item \textbf{Test Set}: The 30\% test set was kept completely separate from the training process, ensuring that the model's performance could be assessed on data it had never seen before. This provides an unbiased evaluation of the model's accuracy and generalization capabilities.
\end{itemize}

By properly dividing the dataset, this approach ensures that the model is trained on a representative subset of data, can be fine-tuned using the validation set, and is evaluated fairly on the test set. 
This helps in achieving a balance between training the model effectively and ensuring generalization without overfitting or underfitting.

\subsection{Machine Learning Model Development}
This section describes the implementation of the RF model and the RL feedback loop, explaining how these models were integrated to complement each other and enhance prediction accuracy in the system.

\subsubsection{Random Forest Model Implementation}

The \textbf{RF model} is implemented using scikit-learn's \textbf{RandomForestClassifier}. 
It is employed as the core decision-making component in the system, trained to predict two target variables: \textbf{priority} and \textbf{taxonomy} of security alerts. 
To handle these \textbf{multi-output targets}, \textbf{MultiOutputClassifier} is used, which allows the model to make predictions on both target variables simultaneously.

The first step in implementing the \textbf{RF model} is to transform the raw textual data in the \textbf{Description} column into numerical features. 
This is achieved using \textbf{SentenceBertVectorizer}, a tool that leverages the \textbf{Sentence-BERT model} to generate embeddings from the alert descriptions. 
These embeddings capture the \textbf{semantic meaning} of the descriptions, which is crucial for the model to make accurate predictions.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
vectorizer = SentenceBertVectorizer(model_name="paraphrase-MiniLM-L6-v2")
X = vectorizer.fit_transform(df["Description"])
\end{minted}
\captionof{listing}{Vectorizing Text Data.}
\label{lst:vectorizing_text_data}
\end{minipage}
\vspace{0.1cm}

Once the text data is vectorized, the target labels (Priority and Taxonomy) are encoded using LabelEncoder. 
This step converts the categorical labels into numeric form, making them suitable for input into the RF model.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
# Encode targets for Priority and Taxonomy
le_priority = LabelEncoder()
le_taxonomy = LabelEncoder()
y_priority = le_priority.fit_transform(df["Priority"])
y_taxonomy = le_taxonomy.fit_transform(df["Taxonomy"])

# Combine the targets into a 2D array
Y = np.column_stack((y_priority, y_taxonomy))
\end{minted}
\captionof{listing}{Encoding Target Labels.}
\label{lst:encoding_target_labels}
\end{minipage}
\vspace{0.1cm}

Next, the dataset is split into training and testing sets using train\_test\_split from scikit-learn. 
This ensures that the model is trained on one subset of data and evaluated on another, providing an unbiased assessment of its performance.

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)
\end{minted}
\captionof{listing}{Splitting the Dataset.}
\label{lst:splitting_dataset}
\end{minipage}
\vspace{0.1cm}

After splitting the data, the RandomForestClassifier is initialized and wrapped with MultiOutputClassifier to handle the multi-output prediction task. 
The model is trained on the training data and evaluated on the test set. 

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
# Train a MultiOutputClassifier using RandomForest
base_rf = RandomForestClassifier(n_estimators=500, random_state=42, max_depth=40, min_samples_split=10)
multi_rf = MultiOutputClassifier(base_rf)
multi_rf.fit(X_train, Y_train)
\end{minted}
\captionof{listing}{Training the Random Forest Model.}
\label{lst:training_rf_model}
\end{minipage}
\vspace{0.1cm}

\subsubsection{Reinforcement Learning Model Implementation}

While the RF model is capable of making initial predictions, it requires further refinement to adapt to new or unseen threats. 
This is where the RL model comes in. The RL model is designed to improve predictions by incorporating feedback from security analysts.

The RL model is built using the Proximal Policy Optimization (PPO) algorithm from Stable Baselines3, a popular library for RL. 
The model's role is to adjust the predictions made by the RF model based on feedback received from analysts. 

At the core of this RL model is a reward function that is based on whether the model's predictions are correct, focusing on both false positive (FP) and true positive (TP) predictions for taxonomy and priority. 
The reward function is designed to penalize incorrect predictions and reward correct ones, with particular weight given to more critical mistakes.

\paragraph{False Positive (FP) Evaluation}
The third element of the action vector represents the \textbf{RL model's FP prediction}. 

A positive reward is given if the model's FP prediction matches the ground truth, while a penalty is applied if the prediction is incorrect.

\[
R_{\text{FP}} = 
\begin{cases} 
+ w_{\text{tp}} \cdot \text{confidence} & \text{if FP prediction is correct} \\
- w_{\text{fn}} & \text{if predicted FP but true TP} \\
- w_{\text{fp}} & \text{if predicted TP but true FP} \\
\end{cases}
\label{eq:fp_reward}
\]

\paragraph{Priority and Taxonomy Classification}
The \textbf{priority} and \textbf{taxonomy} predictions are compared to the true values. A penalty is applied if either the priority or taxonomy prediction is incorrect.

\[
R_{\text{error}} = \alpha \cdot \text{priority\_error\_indicator} + \beta \cdot \text{taxonomy\_error\_indicator}
\label{eq:error_penalty}
\]

\paragraph{Final Reward}
The final reward is the sum of the FP evaluation and the error penalties for priority and taxonomy:

\[
R = R_{\text{FP}} - R_{\text{error}}
\label{eq:final_reward}
\]

Where:
\begin{itemize}
    \item \( w_{\text{tp}} \) is the weight for true positives,
    \item \( w_{\text{fn}} \) and \( w_{\text{fp}} \) are penalties for false negatives and false positives, respectively,
    \item \( \alpha \) and \( \beta \) are the penalty weights for priority and taxonomy errors,
    \item \textbf{confidence} is the model’s confidence in its FP prediction,
    \item \textbf{priority\_error\_indicator} and \textbf{taxonomy\_error\_indicator} are binary values indicating whether the respective predictions are correct.
\end{itemize}

This reward function allows the RL model to adjust its predictions based on feedback, ensuring continuous improvement in the model's performance.

The RL agent uses the above reward function to adjust its policy (i.e., how it makes predictions) based on the rewards it receives after each prediction. 
The PPO algorithm ensures that policy updates are stable and efficient, making it well-suited for real-time systems.

To manage computational load during training, the RL model is trained asynchronously using Celery, a distributed task queue. 
Celery ensures that training tasks do not block other system operations, enabling the RL model to be trained in parallel with real-time alert classification.

Here's an example of how the RL training task is defined using Celery:

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
@celery_app.task
def train_rl_agent_task(feedback, model_version):
    dummy_env = RLDummyEnv(observation_dim=386)
    rl_agent = PPO.load(src.config.RL_AGENT_PATH, env=dummy_env)

    model = load_model(model_version)
    result_info = update_rl_agent_with_feedback(feedback, model, rl_agent)
    return result_info
\end{minted}
\captionof{listing}{RL Training Task with Celery.}
\label{lst:rl_training_task}
\end{minipage}
\vspace{0.1cm}

This asynchronous processing model allows the RL agent to continuously improve based on real-time feedback while ensuring that the system remains responsive to new alert data.
Although, for this to happen the RL model need to be trained in a separate process to ensure efficient and uninterrupted training. 
However, this separation means that the most recently trained version of the model is not immediately available to the main process responsible for making predictions. 

To address this, the training process saves the model to persistent storage each time training is completed. 

The main process, whenever it needs to use the RL model, checks if the model has been updated since the last time it was loaded. 
If a newer version is detected, the main process reloads the model, ensuring that it always operates with the most up-to-date version of the RL model.
This approach maintains consistency between training and inference while allowing both processes to function independently.

\subsection{Hyperparameter Tuning}

In the process of model development, hyperparameter tuning was performed for both the \gls{RF} and \gls{RL} models to optimize their performance. 

The primary goal of hyperparameter tuning is to find the best configuration of hyperparameters that allows the models to generalize well to unseen data, reducing the risk of overfitting while maintaining high predictive accuracy.

For the \gls{RF} model, tests were run using a \texttt{GridSearchCV} approach to explore a range of hyperparameters. 
However, after extensive testing, the most effective hyperparameters were identified and are now used in the model's initialization. 

\begin{itemize}
    \item \textbf{Number of estimators (\texttt{n\_estimators})}: Set to 500.
    \item \textbf{Maximum depth (\texttt{max\_depth})}: Set to 40.
    \item \textbf{Minimum samples required to split an internal node (\texttt{min\_samples\_split})}: Set to 10.
    \item \textbf{Minimum samples required at each leaf node (\texttt{min\_samples\_leaf})}: Set to 1.
    \item \textbf{Class weight (\texttt{class\_weight})}: Set to \texttt{'balanced'}.
\end{itemize}

The following code snippet reflects the initialization of the RF model with the chosen hyperparameters:

\vspace{0.2cm}
\noindent
\begin{minipage}{\linewidth}
\begin{minted}{python}
base_rf = RandomForestClassifier(n_estimators=500, random_state=42, 
                                max_depth=40, min_samples_split=10, 
                                min_samples_leaf=1, class_weight='balanced')
multi_rf = MultiOutputClassifier(base_rf)
\end{minted}
\captionof{listing}{Random Forest Model Initialization.}
\label{lst:rf_model_initialization}
\end{minipage}
\vspace{0.1cm}

For the \gls{RL} model, a similar approach was used, but the model's hyperparameters, such as learning rate, batch size, and the number of epochs, were fine-tuned to ensure that the model could learn efficiently from feedback while maintaining stability in training. 
The PPO algorithm was used, which is known for its stability and effectiveness in reinforcement learning tasks. 
The key parameters for the \gls{RL} model include:

\begin{itemize}
    \item \textbf{Learning rate}: Set to 3e-4.
    \item \textbf{Batch size}: Set to 64.
    \item \textbf{Number of epochs}: Set to 4.
    \item \textbf{Gamma}: Set to 0.99.
    \item \textbf{GAE lambda}: Set to 0.9.
    \item \textbf{Entropy coefficient}: Set to 0.01.
\end{itemize}

The \gls{RL} model's training process is designed to adjust its predictions based on the feedback it receives, improving accuracy over time by refining its policy.

Both models underwent comprehensive testing to determine the optimal set of hyperparameters. Ultimately, the configurations used in the models' initialization were found to provide the best balance between performance, accuracy, and generalization.

The finalized hyperparameters are now used in the model pipelines, ensuring efficient training and reliable predictions.
